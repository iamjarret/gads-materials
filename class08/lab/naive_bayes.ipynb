{
 "metadata": {
  "name": "",
  "signature": "sha256:15d185623a29c3a85d9428d25b62bb1208bd47818eea278636388a7de075263b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Naive Bayes Classification\n",
      "\n",
      "Concepts in this Notebook:\n",
      "- Naive Bayes Classifiers\n",
      "- Train Test Split\n",
      "- Vectorizer (fit and transform)\n",
      "- Accuracy of training and test data\n",
      "- Sparse array vs normal array\n",
      "- Comparing classifiers in sklearn\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some extra resources:\n",
      "\n",
      "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
      "\n",
      "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics = pd.read_csv('/home/vagrant/notebooks/fall_2014_lessons/datasets/rt_critics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.quote[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'A winning animated feature that has something for everyone on the age spectrum.'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Multinomial vs Bernoulli Models\n",
      "\n",
      "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
      "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import BernoulliNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### How the Count Vectorizer Works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "### How the Count Vectorizer Works\n",
      "#\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
      "print \"Original text:\\n\\t\", '\\n\\t'.join(text)\n",
      "\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
      "\n",
      "# call `fit` to build the vocabulary\n",
      "vectorizer.fit(text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original text:\n",
        "\tMath is great\n",
        "\tMath is really great\n",
        "\tExciting exciting Math\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q: What is an ngram?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# display the names of the features\n",
      "vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[u'exciting',\n",
        " u'exciting exciting',\n",
        " u'exciting math',\n",
        " u'great',\n",
        " u'is',\n",
        " u'is great',\n",
        " u'is really',\n",
        " u'math',\n",
        " u'math is',\n",
        " u'really',\n",
        " u'really great']"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call `transform` to convert text to a bag of words\n",
      "x = vectorizer.transform(text)\n",
      "print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3)\t1\n",
        "  (0, 4)\t1\n",
        "  (0, 5)\t1\n",
        "  (0, 7)\t1\n",
        "  (0, 8)\t1\n",
        "  (1, 3)\t1\n",
        "  (1, 4)\t1\n",
        "  (1, 6)\t1\n",
        "  (1, 7)\t1\n",
        "  (1, 8)\t1\n",
        "  (1, 9)\t1\n",
        "  (1, 10)\t1\n",
        "  (2, 0)\t2\n",
        "  (2, 1)\t1\n",
        "  (2, 2)\t1\n",
        "  (2, 7)\t1\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
      "# convert back to a \"normal\" numpy array\n",
      "x_back = x.toarray()\n",
      "x_back"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
        "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
        "       [2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Transformed text vector is \\n\", x\n",
      "\n",
      "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
      "print\n",
      "print \"Words for each feature:\"\n",
      "print vectorizer.get_feature_names()\n",
      "\n",
      "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
      "# just their frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Transformed text vector is \n",
        "  (0, 3)\t1\n",
        "  (0, 4)\t1\n",
        "  (0, 5)\t1\n",
        "  (0, 7)\t1\n",
        "  (0, 8)\t1\n",
        "  (1, 3)\t1\n",
        "  (1, 4)\t1\n",
        "  (1, 6)\t1\n",
        "  (1, 7)\t1\n",
        "  (1, 8)\t1\n",
        "  (1, 9)\t1\n",
        "  (1, 10)\t1\n",
        "  (2, 0)\t2\n",
        "  (2, 1)\t1\n",
        "  (2, 2)\t1\n",
        "  (2, 7)\t1\n",
        "\n",
        "Words for each feature:\n",
        "[u'exciting', u'exciting exciting', u'exciting math', u'great', u'is', u'is great', u'is really', u'math', u'math is', u'really', u'really great']\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Preparing our Features (X) and Target (Y) for Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
      "\n",
      "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a vector where each row is bag-of-words for a single quote\n",
      "X = vectorizer.fit_transform(critics.quote) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# temporary variable\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create an array where each element encodes whether the array is Fresh or Rotten\n",
      "Y = (critics.fresh == 'fresh').values.astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use SKLearn's train_test_split \n",
      "from sklearn.cross_validation import train_test_split\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating the Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy_report(_clf):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "print \"MultinomialNB:\"\n",
      "clf = MultinomialNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MultinomialNB:\n",
        "Accuracy: 78.00%\n",
        "Accuracy on training data: 0.99"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "print \"BernoulliNB:\"\n",
      "clf = BernoulliNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB:\n",
        "Accuracy: 65.89%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.87"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "print \"Logistic Regression:\"\n",
      "clf = LogisticRegression().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression:\n",
        "Accuracy: 76.83%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a function to run some tests\n",
      "def AnalyzeReview(testquote):\n",
      "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
      "    testquote = rotten_vectorizer.transform([testquote])\n",
      "\n",
      "    if (clf.predict(testquote)[0] == 1):\n",
      "        print \"... a fresh review.\"\n",
      "    else:\n",
      "        print \"... a rotten review.\"\n",
      "    return(clf.predict(testquote)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeReview(\"This movie was awesome\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"This movie was awesome\" is judged by clasifier to be...\n",
        "... a rotten review.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save prediction and probability\n",
      "\n",
      "# Outputs of X (just first column)\n",
      "prob = clf.predict_proba(X)[:, 0]\n",
      "\n",
      "predict = clf.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y==0 #(provides a mask where the actual review is bad)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([False, False, False, ..., False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# argsort returns the positions of the top n sorted values\n",
      "np.argsort((prob[Y==0]))[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([5214, 2972, 2124, 1211, 3304])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Review errors\n",
      "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
      "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Mis-predicted Rotten quotes\"\n",
      "print '---------------------------'\n",
      "for row in bad_rotten:\n",
      "    print critics[Y == 0].quote.irow(row)\n",
      "    print\n",
      "\n",
      "print \"Mis-predicted Fresh quotes\"\n",
      "print '--------------------------'\n",
      "for row in bad_fresh:\n",
      "    print critics[Y == 1].quote.irow(row)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mis-predicted Rotten quotes\n",
        "---------------------------\n",
        "Benefits from a lively lead performance by the miscast Denzel Washington but doesn't come within light years of the book, one of the greatest American autobiographies.\n",
        "\n",
        "With the exception of Miss Streep's performance, the pleasures of Out of Africa are all peripheral -- David Watkin's photography, the landscapes, the shots of animal life -all of which would fit neatly into a National Geographic layout.\n",
        "\n",
        "Night Watch works better as a demo reel for the state of Russian effects work than as a first installment in an epic trilogy.\n",
        "\n",
        "[Lawrence is] a charming, gifted comic with a killer smile, but he's way out of his depth in this Fatal Attraction knockoff, which he also co-wrote and stars in.\n",
        "\n",
        "...it does not have a great script, great performances or great direction.\n",
        "\n",
        "Mis-predicted Fresh quotes\n",
        "--------------------------\n",
        "More of a cinematic joke book than a real movie, Spy Hard hits you with gags faster than Henny Youngman on speed. Even when individual bits misfire, the unrelenting barrage of silliness can break down your resistance.\n",
        "\n",
        "Best stuff here comes strsight from Martin, such as his frenzied antics in the in-laws' house or his ridiculous Tom Jones imitation in front of a mirror in a too-tight tuxedo.\n",
        "\n",
        "It sounds like the stuff of soap operas or bad porn, but Kureishi's script is too intelligent and empathetic to titillate.\n",
        "\n",
        "There's not a believable minute in the 92 minutes of Last Chance Harvey, but Dustin Hoffman and Emma Thompson smooth over most of the problems just by showing up and doing what they do for a living.\n",
        "\n",
        "The movie's basic joke holds that the overbearing, unselfconscious Americans will do anything and say anything (and usually as loudly as possible), while the timorous British are nearly too polite to breathe.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}